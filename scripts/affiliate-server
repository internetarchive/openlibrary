#!/usr/bin/env python
"""Run affiliate server.

Usage:

start affiliate-server using dev webserver:

    ./scripts/affiliate-server openlibrary.yml 31337

start affiliate-server as fastcgi:

    ./scripts/affiliate-server openlibrary.yml fastcgi 31337

start affiliate-server using gunicorn webserver:

    ./scripts/affiliate-server openlibrary.yml --gunicorn -b 0.0.0.0:31337

"""

import json
import logging
import os
import queue
import sys
import threading
import time

import web
import yaml

import _init_path  # noqa: F401  Imported for its side effect of setting PYTHONPATH

import infogami
from infogami import config
from openlibrary.core import stats
from openlibrary.core.vendors import AmazonAPI
from openlibrary.utils.dateutil import WEEK_SECS
from openlibrary.utils.isbn import (
    normalize_isbn, isbn_13_to_isbn_10, isbn_10_to_isbn_13)

logger = logging.getLogger("affiliate-server")

urls = (
    '/isbn/([0-9X-]+)', 'Submit',
    '/status', 'Status',
)

API_MAX_ITEMS_PER_CALL = 10
API_MAX_WAIT_SECONDS = 0.9

web.amazon_queue = queue.Queue()  # a thread-safe multi-producer, multi-consumer queue


def process_amazon_batch(isbn_10s):
    """
    def process_amazon_batch(isbn_10s: list[str]) -> None:

    Call the Amazon API to get the products for a list of isbn_10s and store
    each product in memcache using amazon_product_{isbn_13} as the cache key.
    """
    logger.info("process_amazon_batch(): {} items".format(len(isbn_10s)))
    try:
        products = web.amazon_api.get_products(isbn_10s, serialize=True)
    except Exception:
        logger.exception("amazon_api.get_product({}, serialize=True)".format(isbn_10s))
        products = []
    for product in products:
        # Make sure we have an isbn_13 for cache key
        cache_key = (
            product.get('isbn_13') and product.get('isbn_13')[0] or
            isbn_10_to_isbn_13(product.get('isbn_10')[0])
        )
        cache.memcache_cache.set(
            'amazon_product_%s' % cache_key, product, expires=WEEK_SECS
        )


def seconds_remaining(start_time):
    """
    def seconds_remaining(start_time: int) -> int:
    """
    return max(API_MAX_WAIT_SECONDS - (time.time() - start_time), 0)


def amazon_lookup():
    """
    def amazon_lookup() -> None:

    A separate thread of execution that uses the time up to API_MAX_WAIT_SECONDS to
    create a list of isbn_10s that is not larger than API_MAX_ITEMS_PER_CALL and then
    passes them to process_amazon_batch()
    """
    while True:
        start_time = time.time()
        isbn_10s = set()  # no duplicates in the batch
        while len(isbn_10s) < API_MAX_ITEMS_PER_CALL and seconds_remaining(start_time):
            try:  # queue.get() will block (sleep) until successful or it times out
                isbn_10s.add(
                    web.amazon_queue.get(timeout=seconds_remaining(start_time))
                )
            except queue.Empty:
                pass
        if isbn_10s:
            time.sleep(seconds_remaining(start_time))
            process_amazon_batch(list(isbn_10s))


threading.Thread(target=amazon_lookup).start()

class Status:
    def GET(self):
        return json.dumps({
            "queue_size": web.amazon_queue.qsize(),
            "queue": list(web.amazon_queue.queue),
        })


class Submit:

    @classmethod
    def unpack_isbn(cls, isbn):
        isbn = normalize_isbn(isbn.replace('-', ''))
        isbn10 = isbn if len(isbn) == 10 else isbn.startswith('978') and isbn_13_to_isbn_10(isbn)
        isbn13 = isbn if len(isbn) == 13 else isbn_10_to_isbn_13(isbn)
        return isbn10, isbn13

    def GET(self, isbn):
        """
        If isbn is in memcache then return the `hit`.  If not then queue the isbn to be
        looked up and return the equivalent of a promise as `submitted`
        """
        if not web.amazon_api:
            return json.dumps({"error": "not_configured"})

        isbn10, isbn13 = self.unpack_isbn(isbn)
        if not isbn10:
            return json.dumps({
                "error": "rejected_isbn",
                "isbn10": isbn10,
                "isbn13": isbn13
            })

        # Cache lookup by isbn13. If there's a hit return the product to the caller
        product = cache.memcache_cache.get('amazon_product_%s' % isbn13)
        if product:
            return json.dumps({"status": "success", "hit": product})

        # Cache misses will be submitted to Amazon as ASINs (isbn10)
        if isbn10 not in web.amazon_queue.queue:
            web.amazon_queue.put_nowait(isbn10)
        qsize = web.amazon_queue.qsize()
        stats.put("Amazon queue qsize", qsize, 0.05)  # send one sample in 20 to statsd
        return json.dumps({"status": "submitted", "queue": qsize})


def load_config(configfile):
    infogami.load_config(configfile)

    #if 'fastcgi' in d:
    #    web.config.fastcgi = d['fastcgi']

    web.amazon_api = None
    args = [
        config.amazon_api.get('key'),
        config.amazon_api.get('secret'),
        config.amazon_api.get('id')
    ]
    if all(args):
        web.amazon_api = AmazonAPI(*args, throttling=0.9)
        logger.info("AmazonAPI Initialized")
    else:
        raise RuntimeError("{} is missing required keys.".format(configfile))


def init_sentry(app):
    from openlibrary.utils.sentry import Sentry
    sentry = Sentry(getattr(config, 'sentry', {}))
    if sentry.enabled:
        sentry.init()
        sentry.bind_to_webpy_app(app)

def setup_env():
    # make sure PYTHON_EGG_CACHE is writable
    os.environ['PYTHON_EGG_CACHE'] = "/tmp/.python-eggs"

    # required when run as fastcgi
    os.environ['REAL_SCRIPT_NAME'] = ""

cache = None

def start_server():
    sysargs = sys.argv[1:]
    configfile, args = sysargs[0], sysargs[1:]

    # type: (str) -> None
    load_config(configfile)
    global cache
    from openlibrary.core import cache
    # sentry could be loaded here
    # init_sentry(app)

    sys.argv = [sys.argv[0]] + list(args)
    app.run()

def start_gunicorn_server():
    """Starts the affiliate server using gunicorn server.
    """
    from gunicorn.app.base import Application

    configfile = sys.argv.pop(1)

    class WSGIServer(Application):
        def init(self, parser, opts, args):
            pass

        def load(self):
            load_config(configfile)
            # init_setry(app)
            return app.wsgifunc(https_middleware)

    WSGIServer("%prog openlibrary.yml --gunicorn [options]").run()


def https_middleware(app):
    """Hack to support https even when the app server http only.

    The nginx configuration has changed to add the following setting:

        proxy_set_header X-Scheme $scheme;

    Using that value to overwrite wsgi.url_scheme in the WSGI environ,
    which is used by all redirects and other utilities.
    """
    def wrapper(environ, start_response):
        if environ.get('HTTP_X_SCHEME') == 'https':
            environ['wsgi.url_scheme'] = 'https'
        return app(environ, start_response)
    return wrapper


def runfcgi(func, addr=('localhost', 8000)):
    """Runs a WSGI function as a FastCGI pre-fork server."""
    config = dict(web.config.get("fastcgi", {}))

    mode = config.pop("mode", None)
    if mode == "prefork":
        import flup.server.fcgi_fork as flups
    else:
        import flup.server.fcgi as flups

    return flups.WSGIServer(func, multiplexed=True, bindAddress=addr, **config).run()


web.config.debug = False
web.wsgi.runfcgi = runfcgi

app = web.application(urls, locals())


if __name__ == "__main__":
    setup_env()
    if "--gunicorn" in sys.argv:
        sys.argv.pop(sys.argv.index("--gunicorn"))
        start_gunicorn_server()
    else:
        start_server()
